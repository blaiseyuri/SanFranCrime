{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "Random Forest is one of my favorite methods because it is pretty easy to use and returns pretty good results. The data has already been cleaned up so I can get straight to the modeling from here. I'll also be creating a table of results I get from the algorithm. The first table will be based on performance and accuracy I'll be manipulating the data and my settings to get the best result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is some data from earlier runs that I did earlier in the week. I don't have enough RAM on my computer to run a proper Random Forest on the full data set so I tried changing some of the settings to see what type of results I would get, so far it things don't look so great.\n",
    "\n",
    "| Out of bag Score               | Depth | Trees |\n",
    "|---------------------|-------|-------|\n",
    "| 0.24406610565014025 | 7     | 250   |\n",
    "| 0.243709633517      | 7     | 500   |\n",
    "| 0.244111661194      | 7     | 750   |\n",
    "| 0.243918050132      | 7     | 1000  |\n",
    "| 0.29118306609312239 | 15    | 250   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "Y = pd.read_csv('./data/Y.csv', index_col = 0, header=None, names=['Crime'])\n",
    "X = pd.read_csv('./data/X.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rows = np.random.choice(X.index.values, X.shape[0])\n",
    "a = X.ix[rows]\n",
    "b = Y['Crime'].ix[rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.ensemble as sk\n",
    "n = 25\n",
    "rfc = sk.RandomForestClassifier(n_estimators = n, oob_score = True, bootstrap = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1% 80mb 453ms 18.34% 25\n",
    "# 1% 750mb 3.52ms 22.79% 250\n",
    "# 1% 2500\n",
    "# 1% 2800mb 13.4s 24.27% 1000\n",
    "# 10% 700mb 4.07s 27.91% 25\n",
    "# 30% 1700mb 13.5s 40.68% 25\n",
    "# 30% 100\n",
    "# 30% 4000mb 25.5s 42.39% 50\n",
    "# 50% 31000mb 24.7s 49.38% 25\n",
    "# 70% 4200mb  38.7s 55.92% 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2015\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:379: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.63114814776851857"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time rfc.fit(a,b)\n",
    "rfc.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On my 2nd try with Random Forest I focused more on my different parameters than anything else. After experimenting with different settings I was able too get some improvements from my past scores but I still have a ways to go.\n",
    "\n",
    "| Sample Size | Memory (RAM) | Time  | oob Score | Estimators | Comments and Notes                                                           |\n",
    "|-------------|--------------|-------|-----------|------------|------------------------------------------------------------------------------|\n",
    "| 1%          |              |       |           | 2500       | Memory went over 5000Mb process was ended                                    |\n",
    "| 1%          | 2800Mb       | 13.4s | 24.27%    | 1000       |                                                                              |\n",
    "| 10%         | 1700Mb       | 4.07s | 27.91%    | 25         |                                                                              |\n",
    "| 30%         | 4000Mb       | 25.5s | 42.39%    | 50         |                                                                              |\n",
    "| 50%         | 3100Mb       | 24.7s | 49.28%    | 25         | Given warning that some inputs did not have OOB scores, due to too few trees |\n",
    "| 70%         | 4200Mb       | 38.7s | 55.92%    | 25         | Given warning that some inputs did not have OOB scores, due to too few trees |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "Z = df.drop(['Category','Descript','Resolution','X','Y'],1)\n",
    "n = 0\n",
    "for col in Z.columns:\n",
    "    if n < 4:\n",
    "        Z[col] = Z[col].astype('category')\n",
    "        Z[col] = Z[col].cat.rename_categories(range(0,Z[col].nunique()))\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.61514291788359043"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time rfc.fit(Z.ix[rows],b)\n",
    "rfc.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#70% 4400Mb N/A 52.89% 25 all but X,Y\n",
    "#50% 50 all but X,Y\n",
    "#50% 25 all but X,Y,Day\n",
    "#50% 1300Mb 20.2s 30% 25 DayofWeek, Address\n",
    "#80% 1600Mb 34.2s 33.17% 25 DayofWeek, Address\n",
    "#80%  5200Mb 5min 30s 33.41% 100 DayofWeek, Address\n",
    "#80% 800Mb  32.6s 30.89% 25 PdDistrict, Address, X, Y\n",
    "#80% 2000Mb  35.7s 36.72% 25 All but day Month year\n",
    "#100% 2300Mb  46s 37.88% 25 All but day Month year\n",
    "#70% 4400Mb 52.6s 56.80% 25 original data\n",
    "#70% 4400Mb 50.5s 56.73% 25 original data without XY\n",
    "#80% 5000Mb 55s 58.79% 25 original data without XY\n",
    "#90% 5000Mb 55s 61.15% 25 original data without XY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slimming Down my data back to the original features really improved the performance and accuracy of my models. By Dropping the X,Y columns I was able to get the oob_score up to 61%\n",
    "\n",
    "| Sample Size | Memory | time  | Oob Score | Estimators | Data Columns               |\n",
    "|-------------|--------|-------|-----------|------------|----------------------------|\n",
    "| 70%         | 4400Mb | N/A   | 52.89%    | 25         | all but X,Y                |\n",
    "| 100%        | 2300Mb | 46s   | 37.88%    | 25         | All but Day Month and Year |\n",
    "| 80%         | 800Mb  | 32.6s | 30.89%    | 25         | PdDistrict, Address, X, Y  |\n",
    "| 70%         | 4400Mb | 52.6s | 56.80%    | 25         | Original Data              |\n",
    "| 80%         | 5000Mb | 55s   | 58.79%    | 25         | Original Data w/o X,Y      |\n",
    "| 90%         | 5000Mb | 55s   | 61.15%    | 25         | Original Data w/o X,Y      |\n",
    "| 100%         | 5000Mb | 1min 53s   | 63.11%    | 25         | Original Data w/o X,Y      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "# joblib.dump(rfc, './models/rf/61rfc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfc = joblib.load('./models/rf/61rfc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62944095375087272"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(Z,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('./data/test.csv', index_col=0)\n",
    "test.drop(['X','Y'],1,inplace=True)\n",
    "n = 0\n",
    "for col in test.columns:\n",
    "    if n < 4:\n",
    "        test[col] = test[col].astype('category')\n",
    "        test[col] = test[col].cat.rename_categories(range(0,test[col].nunique()))\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4h 32min 42s\n"
     ]
    }
   ],
   "source": [
    "%time results = rfc.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wall time: 4h 32min 42s\n",
    "rfc.score = .629\n",
    "Kaggle Score: 33.75118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resultdf = pd.DataFrame(results)\n",
    "resultdf.to_csv('rf_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# categories = df.Category.unique()\n",
    "for i,cat in enumerate(categories):\n",
    "    resultdf.replace(i,cat,inplace=True)\n",
    "resultdf.to_csv('rf_resultsformat.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out the submission wants the probabilities of each crime so I should've used the probablity predict probability method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 44min 7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.   ,  0.08 ,  0.   , ...,  0.16 ,  0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   , ...,  0.12 ,  0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ,  0.   , ...,  0.04 ,  0.   ,  0.   ],\n",
       "       ..., \n",
       "       [ 0.   ,  0.12 ,  0.08 , ...,  0.04 ,  0.04 ,  0.   ],\n",
       "       [ 0.   ,  0.01 ,  0.   , ...,  0.   ,  0.01 ,  0.   ],\n",
       "       [ 0.   ,  0.044,  0.   , ...,  0.   ,  0.04 ,  0.   ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time rfc.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probablity_results = _oh[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pr = pd.DataFrame(probablity_results, columns=df.Category.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pr = pr[sorted(pr.columns.values)]\n",
    "pr.insert(0,'Id',pr.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pr.to_csv('rf_probresults.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This improved score by a little bit and ran a lot faster\n",
    "\n",
    "Time: 1h 44min 7s Score: 28.49762"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
